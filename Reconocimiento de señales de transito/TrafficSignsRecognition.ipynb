{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TrafficSignsRecognition.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1uqlhaVaK608D8n0uY9X0uaZizKWgglKB",
      "authorship_tag": "ABX9TyMEsRWj/Z9VkK/FhjPVfaxn",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Tavo826/DataScience/blob/main/TrafficSignsRecognition.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gQHt8JXw7vqX"
      },
      "source": [
        "Se pretende entrenar un modelo que clasifique señales de tránsito\r\n",
        "\r\n",
        "### Dataset\r\n",
        "\r\n",
        "Contiene más de 50000 imágenes de diferentes señales de tráfico que se clasifican en 43 clases diferentes, el conjunto de datos está desbalanceado, lo que afecta el rendimietno de la red"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v1OcsOSrMh5Q"
      },
      "source": [
        "### Preprocesamiento\r\n",
        "\r\n",
        "Se itera sobre todas las cases y se agregan las imágenes y las respectivas etiquetas en la lista de data y labels"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tvZWWksSmMLQ"
      },
      "source": [
        "# %tensorflow_version 2.x\r\n",
        "# import tensorflow as tf\r\n",
        "# device_name = tf.test.gpu_device_name()\r\n",
        "# if device_name != '/device:GPU:0':\r\n",
        "#   raise SystemError('GPU device not found')\r\n",
        "# print('Found GPU at: {}'.format(device_name))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lCbWLiqP5oe4"
      },
      "source": [
        "import os\r\n",
        "import numpy as np\r\n",
        "import pandas as pd\r\n",
        "import tensorflow as tf\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "\r\n",
        "from PIL import Image\r\n",
        "from keras.models import Sequential\r\n",
        "from keras.utils import to_categorical\r\n",
        "from keras.layers import Conv2D, MaxPool2D, Dense, Flatten, Dropout\r\n",
        "from sklearn.model_selection import train_test_split\r\n",
        "from sklearn.metrics import accuracy_score\r\n",
        "\r\n",
        "os.chdir('/content/drive/MyDrive/Colab Notebooks/Data Science/Reconocimiento de señales de tránsito')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UD3ngH-1QJ-q"
      },
      "source": [
        "data = []\r\n",
        "labels = []\r\n",
        "current_path = os.getcwd()\r\n",
        "classes = len(os.listdir(current_path + '/Train'))\r\n",
        "\r\n",
        "#Recorre las carpetas con las clases\r\n",
        "for i in range(classes):\r\n",
        "  path = os.path.join(current_path, 'Train', str(i))\r\n",
        "  images = os.listdir(path)\r\n",
        "\r\n",
        "  #Modificando las imágenes y agregando a la lista\r\n",
        "  for a in images:\r\n",
        "    try:\r\n",
        "      image = Image.open(path + '/' + a)\r\n",
        "      image = image.resize((30,30))\r\n",
        "      image = np.array(image)\r\n",
        "      data.append(image)\r\n",
        "      labels.append(i)\r\n",
        "    except:\r\n",
        "      print('Error cargando la imagen')\r\n",
        "      break\r\n",
        "\r\n",
        "data = np.array(data)\r\n",
        "labels = np.array(labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IGtzOPa4NFzi"
      },
      "source": [
        "El tamaño del conjunto de datos es (39209,30,30,3) los que significa que hay 39209 imágenes de tamaño 30x30 con 3 canales (RGB)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "njR1AGx2gPiu"
      },
      "source": [
        "print('Data shape', data.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "944aW2yaN_c-"
      },
      "source": [
        "Se separa el conjunto en entrenamiento y testeo, luego se convierten las etiquetas a one-hot encoding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I_0n92zsN2Xf"
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(data, labels, test_size=0.2, random_state=42)\r\n",
        "\r\n",
        "print('Train: ', X_train.shape)\r\n",
        "print('Test: ', X_test.shape)\r\n",
        "\r\n",
        "y_train = to_categorical(y_train, classes)\r\n",
        "y_test = to_categorical(y_test, classes)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P-HkKq0yPXLw"
      },
      "source": [
        "### Construyendo el modelo\r\n",
        "\r\n",
        "Arquitectura de la CNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cz_5u-hePlyy"
      },
      "source": [
        "model = Sequential()\r\n",
        "model.add(Conv2D(filters=32, kernel_size=(5,5), activation='relu', input_sape=X_train.shape[1:]))\r\n",
        "model.add(Conv2D(filters=32, kernel_size=(5,5), activation='relu'))\r\n",
        "model.add(MaxPool2D(pool_size=(2,2)))\r\n",
        "model.add(Dropout(rate=0.25))\r\n",
        "model.add(Conv2D(filters=64, kernel_size=(3,3), activation='relu'))\r\n",
        "model.add(Conv2D(filters=64, kernel_size=(3,3), activation='relu'))\r\n",
        "model.add(MaxPool2D(pool_size=(2,2)))\r\n",
        "model.add(Dropout(rate=0.25))\r\n",
        "model.add(Flatten())\r\n",
        "model.add(Dense(256, activation='relu'))\r\n",
        "model.add(Dropout(rate=0.5))\r\n",
        "model.add(Dense(classes, activation='softmax'))\r\n",
        "\r\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pxf9zpOdU-Yd"
      },
      "source": [
        "### Entrenando y validando el modelo\r\n",
        "\r\n",
        "El modelo funciona con un batch size de 64 y su precisión se estabiliza después de 15 épocas"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Unu03FP8WHyb"
      },
      "source": [
        "batch_size = 54\r\n",
        "epochs = 15\r\n",
        "history = model.fit(X_train, y_train, batch_size=batch_size, epochs=epochs,\r\n",
        "                    validation_data=(X_test,, y_test))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t_z3IQJGXK9s"
      },
      "source": [
        "### Graficando\r\n",
        "\r\n",
        "Se analizan el accuracy y el loss en el entrenamiento y la validación"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qRACwXXqXRiS"
      },
      "source": [
        "plt.figure(0)\r\n",
        "plt.plot(history.history['accuracy'], label='Training accuracy')\r\n",
        "plt.plot(history.history['val_accuracy'], label='val accuracy')\r\n",
        "plt.title('Accuracy')\r\n",
        "plt.xlabel('epochs')\r\n",
        "plt.ylabel('accuracy')\r\n",
        "plt.legend()\r\n",
        "\r\n",
        "plt.figure(1)\r\n",
        "plt.plot(history.history['loss'], label='Training loss')\r\n",
        "plt.plot(history.history['val_loss'], label='val loss')\r\n",
        "plt.title('Loss')\r\n",
        "plt.xlabel('epochs')\r\n",
        "plt.ylabel('loss')\r\n",
        "plt.legend()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sbJXt55KbLCa"
      },
      "source": [
        "### Probando el modelo\r\n",
        "\r\n",
        "Se extrae la dirección de la imagen y la etiqueta y se escalan las imágenes para ingresarlas al modelo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bPQBbooCfYu6"
      },
      "source": [
        "import pandas as pd\r\n",
        "\r\n",
        "y_test = pd.read_csv('Test.csv')\r\n",
        "\r\n",
        "lables = y_test['ClassId'].values\r\n",
        "imgs = y_test['Path'].values\r\n",
        "\r\n",
        "data = []\r\n",
        "\r\n",
        "for img in imgs:\r\n",
        "  image = Image.open(img)\r\n",
        "  image = image.resize((30,30))\r\n",
        "  data.append(np.array(image))\r\n",
        "\r\n",
        "X_test = np.array(data)\r\n",
        "\r\n",
        "pred = model.predic_classes(X_test)\r\n",
        "\r\n",
        "accuracy_score(labels, pred)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
